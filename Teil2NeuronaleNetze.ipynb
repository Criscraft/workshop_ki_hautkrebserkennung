{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teil 2: Kennenlernen des Netzwerks\n",
    "\n",
    "In dem zweiten Praxisteil werden Sie mit einem Faltungsnetz arbeiten. Hier lernen Sie, wie Sie ein Netzwerk erstellen, wie Sie Bilder durch das Netzwerk füttern wie Sie die benötigte Rechenzeit messen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dieser Code kopiert und importiert notwendige Dateien in die virtuelle Maschine von Colab.\n",
    "\"\"\"\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "  if os.getcwd() == '/content':\n",
    "    !git clone 'https://github.com/Criscraft/workshop_ki_hautkrebserkennung.git'\n",
    "    os.chdir('workshop_ki_hautkrebserkennung')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "#from torchsummaryX import summary\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import timeit\n",
    "from models import Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe\n",
    "\n",
    "- Schauen Sie sich den Quellcode für das Netzwerk an (models.py)\n",
    "- Wie sieht die Netzwerkarchitektur aus? Was für Schichten sind dort vorhanden?\n",
    "- Nutzen Sie das Paket ```summary```, um eine Zusammenfassung über das Netzwerk zu erhalten.\n",
    "- Wie viele Ausgänge besitzt das Netzwerk?\n",
    "- Wie viele Parameter besitzt das Netzwerk?\n",
    "- Wir werden später etwa 1000 Bilder zum Training verwenden. Was ergeben sich für Probleme?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()\n",
    "# Erstellung des Torch Devices (cpu). Sofern Sie eine GPU zur Verfügung haben, probieren Sie es mit 'cuda'.\n",
    "device = torch.device(\"cpu\")\n",
    "# Netzwerk auf das Device transferieren\n",
    "model = model.to(device)\n",
    "# Geben Sie die Zusammenfassung von summary aus. Welche Eingabegröße müssen Sie für den forward pass angeben?\n",
    "print(summary(model=model, input_size=(3, 128, 128), device='cpu'))\n",
    "#summary(model, torch.zeros((2, 3, 128, 128)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Forward Pass\n",
    "\n",
    "Sehen Sie das Netzwerk jetzt in Aktion. Generieren Sie zufällige Daten mit der Funktion ```torch.rand```. Dann geben Sie es in das Netzwerk und betrachten die Ausgabe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanzieren Sie das Netzwerk und transferieren Sie es auf das Pytorch Device cpu.\n",
    "model = Network()\n",
    "device = torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "# Erstellen Sie einen zufälligen Tensor der Ausmaße (3, 1, 128, 128) auf dem Pytorch Device.\n",
    "my_tensor = torch.rand(3, 3, 128, 128, device=device)\n",
    "# Berechnen Sie die Ausgabe des Netzwerkes\n",
    "output = model(my_tensor)\n",
    "# Geben Sie die Ausgabe aus\n",
    "print(output)\n",
    "print(F.softmax(output,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe\n",
    "\n",
    "- Wir werden später einen Minibatch mit Bildern in einen Tensor verpacken. Wie ist der Tensor aufgebaut?\n",
    "- Wie sind die Ausgabewerte zu interpretieren, wenn es sich um eine Klassifikationsaufgabe handelt? Tipp: Wenden Sie die Funktion ```F.softmax``` auf die Ausgabe des Netzerkes an.\n",
    "- Was macht die Softmax Funktion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Wie lange dauert der Forward Pass?\n",
    "\n",
    "Zeit ist eine wichtige Ressource, die wir effizient nutzen wollen. Messen Sie die Zeit, die Ihr Rechner benötigt, um auf der CPU einen forward pass durchzuführen. Falls Sie eine GPU zur Verfügung haben, messen Sie auch diese Zeit.\n",
    "\n",
    "Tipp für die Zukunft: Pytorch besitzt einen eigenen Profiler, mit dem Sie die Dauer von Tensorberechnungen auf CPU und GPU untersuchen können. Letztere sind bei anderen Profilern wie CProfiler unsichtbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Legen Sie die Minibatchgröße fest, sowie die Anzahl der Iterationen um einen stabilen Zeitwert zu messen\n",
    "batch_size = 16\n",
    "num_iterations = 50\n",
    "\n",
    "# Setup für die Timer Klasse\n",
    "setup = \"\"\"\\\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from models import Network\n",
    "\n",
    "batch_size = {:d}\n",
    "num_iterations = {:d}\n",
    "\n",
    "model = Network()\n",
    "device = torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "input_tensor = torch.rand(batch_size, 3, 128, 128, device=device)\n",
    "\"\"\".format(batch_size, num_iterations)\n",
    "\n",
    "# Statement für die Timer Klasse\n",
    "statement = 'model(input_tensor)'\n",
    "\n",
    "#TODO: Instanzieren Sie die Timer Klasse und berechnen Sie die mittlere Zeit für einen Forward Pass.\n",
    "t = timeit.Timer(stmt=statement, setup=setup)\n",
    "time_per_batch = t.timeit(number=num_iterations) / num_iterations\n",
    "print(\"forward pass takes approx. {:.5f} seconds for one batch\".format(time_per_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe\n",
    "\n",
    "- Wovon hängt die Schnelligkeit eines Forward Pass ab?\n",
    "- Wie groß ist Ihr Geschwindigkeitsgewinn wenn Sie von der CPU auf die GPU wechseln? Wovon hängt dieser ab?\n",
    "- Wie groß wäre in etwa der Geschwindigkeitsgewinn, wenn Sie von Ihrem System auf eine GPU Farm mit 128 (also sehr vielen) Grafikkarten wechseln?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
