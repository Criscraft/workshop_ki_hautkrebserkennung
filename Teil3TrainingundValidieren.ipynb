{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teil 3: Training und Visualisierung\n",
    "\n",
    "Hier werden Sie ein neuronales Netzwerk auf den Bilddaten trainieren und testen. Stellen Sie Fragen und versuchen Sie, ein tieferes Verständnis von Faltungsnetzen und Pytorch zu entwickeln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dieser Code kopiert und importiert notwendige Dateien in die virtuelle Maschine von Colab.\n",
    "\"\"\"\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "  if os.getcwd() == '/content':\n",
    "    !git clone 'https://github.com/Criscraft/workshop_ki_hautkrebserkennung.git'\n",
    "    os.chdir('workshop_ki_hautkrebserkennung')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from models import Network\n",
    "import utils\n",
    "\n",
    "# Konstanten\n",
    "# TODO: Geben Sie das Verzeichnis Datensatzes an\n",
    "DATA_TRAIN = 'data/train/'\n",
    "DATA_TEST = 'data/test/'\n",
    "MAX_EPOCH = 100\n",
    "BATCH_SIZE = 64\n",
    "TRAIN_LOG_PATH = 'train_log.dat'\n",
    "TEST_LOG_PATH = 'test_log.dat'\n",
    "#TODO: Ändern Sie NO_CUDA auf False, falls Sie Ihre GPU benutzen wollen\n",
    "NO_CUDA = False\n",
    "MODEL_FILE_NAME = 'saved_model.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Vorbereitung des Netzwerks\n",
    "\n",
    "Erstellen Sie ein Netzwerk und transferieren Sie es auf die CPU oder die GPU. Wählen Sie das Device abhängig vom Variablenwert ```use_cuda```. Instanzieren Sie die Fehlerfunktion ```nn.CrossEntropyLoss()``` und einen Optimierer (etwa ```torch.optim.SGD```). Setzen Sie die Lernrate zunächst auf 0.01 und den Impuls (momentum) auf 0.9. Vergessen Sie nicht, dem Optimierer die Parameter des Modells ```model.parameters()``` zur Verfügung zu stellen. Der Optimierer wird nur diese Parameter modifizieren, um die Fehlerfunktion zu minimieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = not NO_CUDA and torch.cuda.is_available()\n",
    "cuda_args = {'num_workers': 2, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "# TODO: Erstellen Sie das Pytorch Device ('cuda', falls use_cuda, 'cpu' falls nicht)\n",
    "device = torch.device(\"cuda\") if use_cuda else torch.device(\"cpu\")\n",
    "\n",
    "# TODO: erstellen Sie das Netzwerk und transferieren Sie dieses auf das Pytorch Device\n",
    "model = Network()\n",
    "#model = models.resnet50(pretrained=True)\n",
    "#model.fc = nn.Linear(512 * 4, 2)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# TODO: erstellen Sie die Fehlerfunktion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO: erstellen Sie den Optimierer (stochastic gradient descent)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgaben\n",
    "\n",
    "- Was bedeutet die Lernrate?\n",
    "- Was bedeutet Momentum oder Impuls?\n",
    "- Was bedeutet num_workers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Vorbereitung der Daten\n",
    "\n",
    "Analog zum ersten Praxisteil erstellen wir für die Trainings- und Validierungsdaten jeweils ein Dataset und einen Dataloader. Wir erstellen unterschiedliche Datasets, da wir unterschiedliche Transformationen auf Trainings- und Validierungsbilder anwenden wollen. Fügen Sie die Transformationen ```transforms.Resize```, ```transforms.ToTensor``` und ```transforms.Normalize``` mittels ```transforms.Compose``` zu einer Transformation zusammen, um die Bilder vorzuverarbeiten. Nutzen Sie für die Normalisierung den Mittelwert und die Standardabweichung, die Sie im ersten Praxisteil bestimmt haben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeugen Sie eine Transformation, die das Eingabebild erst in einen Tensor umformt und anschließend den Tensor normalisiert.\n",
    "norm_mean = (0.7811081, 0.53910863, 0.56149995) # skin cancer dataset mean color\n",
    "norm_std = (0.09854942, 0.08949749, 0.09823854) # skin cancer dataset std \n",
    "#norm_mean = (0.485, 0.456, 0.406) # ImageNet mean color\n",
    "#norm_std = (0.229, 0.224, 0.225) # ImageNet std \n",
    "\n",
    "transformations = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=norm_mean, std=norm_std),\n",
    "    ])\n",
    "\n",
    "# Erstellen Sie jeweils ein dataset für Training und Validierung\n",
    "trainset = ImageFolder(DATA_TRAIN, transform=transformations)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "testset = ImageFolder(DATA_TEST, transform=transformations)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgaben\n",
    "\n",
    "- Haben Sie die Normalisierung der Daten verstanden?\n",
    "- Was passiert, wenn Sie die Trainingsdaten nicht shuffeln?\n",
    "- Prüfen Sie die Größe der beiden Dataloader. Wie viele Minibatches haben sie und wie vielen Bildern entspricht dies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training und Validierung\n",
    "\n",
    "Nun haben Sie es bis zum Herzstück des Codes geschafft - herzlichen Glückwunsch soweit! Jetzt werden Sie die Trainingsschleife schreiben, in der die Parameter des Netzwerks iterativ verbessert werden. Lassen Sie sich Zeit, den Ablauf genau zu verstehen. Ihr Code sollte schließlich:\n",
    "\n",
    "1. Mithilfe der Funktionen ```utils.init_log``` eine Logdatei für die Trainingsergebnisse erzeugen - einmal für die Trainingsdaten und noch einmal für die Validierungsdaten\n",
    "2. In einer for-Schleife über die Epochen iterieren. Nutzen Sie die Funktion tqdm, um einen Ladebalken darzustellen.\n",
    "3. In einer Schleife über die Minibatches der Trainingsdaten iterieren, mit den Minibatches einen Forward Pass durchführen, den Fehler berechnen und die Parameter des Netzwerkes bei einem Optimierungsschritt anpassen\n",
    "4. Den aktuellen Fehler und die Genauigkeit auf den Trainingsdaten in die Logdatei schreiben mit ```utils.write_log```.\n",
    "5. In einer Schleife über die Minibatches der Validierungsdaten iterieren, mit den Minibatches einen Forward Pass durchführen und den Fehler berechnen.\n",
    "6. Den aktuellen Fehler und die Genauigkeit auf den Validierungsdaten in die Logdatei schreiben.\n",
    "7. Wenn MAX_EPOCH erreicht ist und das Training beendet ist, das Netzwerk auf der Platte abspeichern. Wir werden Ihr trainiertes Netzwerk morgen noch einmal benötigen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Initialisieren Sie die beiden Logdateien mit utils.init_log für das Training und das Testen\n",
    "utils.init_log(TRAIN_LOG_PATH)\n",
    "utils.init_log(TEST_LOG_PATH)\n",
    "\n",
    "for epoch in tqdm(range(1, MAX_EPOCH + 1)):\n",
    "    \n",
    "    ### Training ###\n",
    "    \n",
    "    # Leere Listen 'losses' und 'correct' erstellen. Dort werden wir Zwischenergebnisse akkumulieren.\n",
    "    losses = []\n",
    "    correct = []\n",
    "    n_images = 0\n",
    "    \n",
    "    # WICHTIG! Das Netzwerk in den Trainingsmodus umschalten!\n",
    "    model.train()\n",
    "    \n",
    "    for data, target in train_loader:\n",
    "        # Nebenschleife über die Training Minibatches\n",
    "        \n",
    "        n_images += len(target)\n",
    "        \n",
    "        # Transferieren Sie data und target auf das Pytorch Device\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        # Die gespeicherten Gradienten auf 0 setzen\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Berechnen Sie die Ausgabe des Netzwerkes\n",
    "        outputs = model(data)\n",
    "        \n",
    "        # Berechnen Sie den Fehler auf dem Batch\n",
    "        loss_batch = criterion(outputs, target)\n",
    "\n",
    "        # Bestimmen Sie die vorhergesagen Labels für die Samples im Batch (Tipp: Benutzen Sie argmax)\n",
    "        pred = outputs.argmax(1)\n",
    "        \n",
    "        # Zählen Sie, wie viele Labels korrekt vorausgesagt wurden.\n",
    "        correct_batch = (target == pred).sum()\n",
    "        \n",
    "        # Berechnung der Gradienten\n",
    "        loss_batch.backward()\n",
    "        \n",
    "        # Optimierungsschritt\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Fügen Sie den Listen 'losses' und 'correct' den aktuellen loss und die Anzahl korrekter Vorhersagen hinzu (Tipp: Benutzen Sie append)\n",
    "        losses.append(loss_batch.item())\n",
    "        correct.append(correct_batch.item())\n",
    "        \n",
    "    # Wandeln Sie die Listen 'losses' und 'correct' in ndarrays um.\n",
    "    losses = np.array(losses)\n",
    "    correct = np.array(correct)\n",
    "    \n",
    "    # Berechnen Sie den mittleren Fehler und die mittlere Genauigkeit. Achtung: der loss ist bereits auf den Minibatch gemittelt.\n",
    "    loss = losses.mean()\n",
    "    accuracy = correct.sum() / n_images\n",
    "    \n",
    "    # Nutzen Sie die write_log Funktion in utils, um die Zwischenergebnisse zu speichern.\n",
    "    utils.write_log(TRAIN_LOG_PATH, epoch, loss, accuracy)\n",
    "    \n",
    "    \n",
    "    ### Validierung ###\n",
    "    \n",
    "    # Leere Listen 'losses' und 'correct' erstellen. Dort werden wir Zwischenergebnisse akkumulieren.\n",
    "    losses = []\n",
    "    correct = []\n",
    "    n_images = 0\n",
    "    \n",
    "    # WICHTIG! Das Netzwerk in den Testmodus umschalten!\n",
    "    model.eval()\n",
    "    \n",
    "    # WICHTIG! Zur Validierung die Berechnung der Gradienten ausstellen!\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            # Nebenschleife über die Test Minibatches\n",
    "            \n",
    "            n_images += len(target)\n",
    "            \n",
    "            # Transferieren Sie data und target auf das Pytorch Device\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            # Berechnen Sie die Ausgabe des Netzwerkes\n",
    "            outputs = model(data)\n",
    "            \n",
    "            # Berechnen Sie den Fehler auf dem Batch\n",
    "            loss_batch = criterion(outputs, target)\n",
    "            \n",
    "            # Bestimmen Sie die vorhergesagen Labels für die Samples im Batch\n",
    "            pred = outputs.argmax(1)\n",
    "            \n",
    "            # Zählen Sie, wie viele Labels korrekt vorausgesagt wurden.\n",
    "            correct_batch = (target == pred).sum()\n",
    "            \n",
    "            # Fügen Sie den Listen 'losses' und 'correct' den aktuellen loss und die Anzahl korrekter Vorhersagen hinzu\n",
    "            losses.append(loss_batch.item())\n",
    "            correct.append(correct_batch.item())\n",
    "        \n",
    "    # Wandeln Sie die Listen 'losses' und 'correct' in ndarrays um.\n",
    "    losses = np.array(losses)\n",
    "    correct = np.array(correct)\n",
    "    \n",
    "    # Berechnen Sie den mittleren Fehler und die mittlere Genauigkeit. Achtung: der loss ist bereits auf den Minibatch gemittelt.\n",
    "    loss = losses.mean()\n",
    "    accuracy = correct.sum() / n_images\n",
    "    \n",
    "    # TODO: Nutzen Sie die write_log Funktion in utils, um die Zwischenergebnisse zu speichern.\n",
    "    utils.write_log(TEST_LOG_PATH, epoch, loss, accuracy)\n",
    "\n",
    "# Abspeichern des trainierten Netzwerks\n",
    "torch.save(model.state_dict(), MODEL_FILE_NAME)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgaben\n",
    "\n",
    "- Stellen Sie sicher, dass Sie die wesentlichen Schritte verstanden haben. Stellen Sie Fragen!\n",
    "- An welcher stelle werden die Gradienten berechnet?\n",
    "- Warum müssen wir nach jedem Batch die Gradienten zurücksetzen?\n",
    "- An welcher Stelle werden die Gewichte des Netzwerkes verändert?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Jetzt sind Sie dran!\n",
    "\n",
    "Hier ein paar Ideen, wie Sie Ihren Algorithmus verbessern können:\n",
    "\n",
    "- Augmentieren Sie Ihre Trainingsdaten: Bildausschnitte, Skalierung, Kontraständerungen, Weißes Rauschen, Spiegelung, ... was hilft Ihnen bei diesem Problem weiter? Das Paket torchvision hat einige nützliche Funktionen zu bieten!\n",
    "- Ändern Sie Ihre Netzwerkarchitektur: Machen Sie das Netzwerk tiefer, flacher, weiter oder schmaler. Wie wirken sich Ihre Modifikationen auf Überanpassung und Genauigkeit aus?\n",
    "- Modifizieren Sie die Lernrate. Probieren Sie, die Lernrate nach einiger Zeit zu verringern. Gewinnen Sie dadurch an Genauigkeit?\n",
    "- Benutzen Sie einen anderen Optimierer wie Adam.\n",
    "- Nutzen Sie Regularisierung: Experimentieren Sie z.B. mit Momentum oder Weight Decay. \n",
    "- Nutzen Sie ein vortrainiertes Netzwerk\n",
    "- Falls Sie noch nicht genug haben: Trainieren Sie mehrere Netzwerke (nach einander), bündeln Sie sie zu einem Ensemble und nutzen Sie für die Validierung ihre gemittelte Ausgabe. Was müssen Sie bei der Mittelung der Ausgaben beachten?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
